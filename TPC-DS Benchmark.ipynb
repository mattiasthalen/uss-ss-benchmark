{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b63a6b6b-d1f7-4a03-b4c3-62b7e7bf3e41",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# DAX Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795af1e4-3231-47c4-bca3-35d7790e613c",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sempy.fabric as fabric\n",
    "import statistics as stats\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e83bd15-38c3-4f7b-a047-5bb8edeca638",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ce30ab-afbc-4127-a8fb-c506967caf2e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "WORKSPACE = None  # same workspace as notebook/lakehouse; set name/ID if needed\n",
    "\n",
    "DATASETS = {\n",
    "    \"SS\": \"Star Schema\",\n",
    "    \"USS\": \"Unified Star Schema\",\n",
    "}\n",
    "\n",
    "MIN_MEASURED = 5        # don't stop before this many measured runs\n",
    "MAX_MEASURED = 100      # hard cap\n",
    "WARMUP = 2              # still run warmups, but store them\n",
    "CV_TARGET = 0.05        # 5% coefficient of variation\n",
    "ERROR_LIMIT = 3         # if a query errors too much, stop early\n",
    "\n",
    "MAX_RESULT_ROWS_TO_STORE = 200_000  # safety cap\n",
    "\n",
    "OUT_DB = \"benchmarks\"\n",
    "RUNS_TABLE = \"runs\"\n",
    "RESULTS_TABLE = \"results\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdee190-ef63-4927-ae87-1ef0f7dc4c6e",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Query Suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6783f55-2ce9-4a04-94ed-5af625791f4c",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "QUERY_TEMPLATES = [\n",
    "    (\"P1_sales_by_year\", \"\"\"\n",
    "EVALUATE\n",
    "SUMMARIZECOLUMNS(\n",
    "    'dim__date'[year],\n",
    "    \"Sales\", SUM('{fact}'[_measure__sales__ext_sales_price])\n",
    ")\n",
    "ORDER BY 'dim__date'[year]\n",
    "\"\"\"),\n",
    "\n",
    "    (\"P2_sales_by_year_category\", \"\"\"\n",
    "EVALUATE\n",
    "SUMMARIZECOLUMNS(\n",
    "    'dim__date'[year],\n",
    "    'dim__item'[category],\n",
    "    \"Sales\", SUM('{fact}'[_measure__sales__ext_sales_price])\n",
    ")\n",
    "ORDER BY 'dim__date'[year], 'dim__item'[category]\n",
    "\"\"\"),\n",
    "\n",
    "    (\"P3_sales_many_groups\", \"\"\"\n",
    "EVALUATE\n",
    "SUMMARIZECOLUMNS(\n",
    "    'dim__date'[year],\n",
    "    'dim__item'[category],\n",
    "    'dim__store'[_key__dim__store],\n",
    "    \"Sales\", SUM('{fact}'[_measure__sales__ext_sales_price])\n",
    ")\n",
    "\"\"\"),\n",
    "\n",
    "    (\"P4_top100_items_sales_2002\", \"\"\"\n",
    "EVALUATE\n",
    "TOPN(\n",
    "    100,\n",
    "    SUMMARIZECOLUMNS(\n",
    "        'dim__item'[_key__dim__item],\n",
    "        'dim__item'[category],\n",
    "        TREATAS( {{ 2002 }}, 'dim__date'[year] ),\n",
    "        \"Sales\", SUM('{fact}'[_measure__sales__ext_sales_price])\n",
    "    ),\n",
    "    [Sales], DESC,\n",
    "    'dim__item'[_key__dim__item], ASC\n",
    ")\n",
    "\"\"\"),\n",
    "\n",
    "    (\"P5_net_sales_by_month\", \"\"\"\n",
    "EVALUATE\n",
    "SUMMARIZECOLUMNS(\n",
    "    'dim__date'[year],\n",
    "    'dim__date'[month_of_year],\n",
    "    \"Sales\",   SUM('{fact}'[_measure__sales__ext_sales_price]),\n",
    "    \"Returns\", SUM('{fact_ret}'[_measure__returns__return_amt]),\n",
    "    \"Net\",\n",
    "        SUM('{fact}'[_measure__sales__ext_sales_price])\n",
    "        - SUM('{fact_ret}'[_measure__returns__return_amt])\n",
    ")\n",
    "ORDER BY 'dim__date'[year], 'dim__date'[month_of_year]\n",
    "\"\"\"),\n",
    "\n",
    "    (\"P9_inventory_wh_category_year_2002\", \"\"\"\n",
    "EVALUATE\n",
    "SUMMARIZECOLUMNS(\n",
    "    'dim__warehouse'[_key__dim__warehouse],\n",
    "    'dim__item'[category],\n",
    "    TREATAS( {{ 2002 }}, 'dim__date'[year] ),\n",
    "    \"Qty On Hand\", SUM('{fact_inv}'[_measure__inventory__qty_on_hand])\n",
    ")\n",
    "\"\"\"),\n",
    "\n",
    "    # -------------------------\n",
    "    # NEW: Time intelligence (YoY)\n",
    "    # -------------------------\n",
    "    (\"P10_sales_yoy_by_year\", \"\"\"\n",
    "EVALUATE\n",
    "ADDCOLUMNS(\n",
    "    SUMMARIZECOLUMNS(\n",
    "        'dim__date'[year],\n",
    "        \"Sales\", SUM('{fact}'[_measure__sales__ext_sales_price])\n",
    "    ),\n",
    "    \"Sales PY\",\n",
    "        CALCULATE(\n",
    "            SUM('{fact}'[_measure__sales__ext_sales_price]),\n",
    "            SAMEPERIODLASTYEAR('dim__date'[date])\n",
    "        ),\n",
    "    \"YoY Î”\",\n",
    "        SUM('{fact}'[_measure__sales__ext_sales_price])\n",
    "        - CALCULATE(\n",
    "            SUM('{fact}'[_measure__sales__ext_sales_price]),\n",
    "            SAMEPERIODLASTYEAR('dim__date'[date])\n",
    "        ),\n",
    "    \"YoY %\",\n",
    "        DIVIDE(\n",
    "            SUM('{fact}'[_measure__sales__ext_sales_price])\n",
    "            - CALCULATE(\n",
    "                SUM('{fact}'[_measure__sales__ext_sales_price]),\n",
    "                SAMEPERIODLASTYEAR('dim__date'[date])\n",
    "            ),\n",
    "            CALCULATE(\n",
    "                SUM('{fact}'[_measure__sales__ext_sales_price]),\n",
    "                SAMEPERIODLASTYEAR('dim__date'[date])\n",
    "            )\n",
    "        )\n",
    ")\n",
    "ORDER BY 'dim__date'[year]\n",
    "\"\"\"),\n",
    "]\n",
    "\n",
    "# SS queries reference multiple physical fact tables; USS uses only _bridge.\n",
    "FACT_FOR_MEASURE_PREFIX = {\n",
    "    \"SS\": {\n",
    "        \"fact\": \"fact__sales\",\n",
    "        \"fact_ret\": \"fact__returns\",\n",
    "        \"fact_inv\": \"fact__inventory\",\n",
    "    },\n",
    "    \"USS\": {\n",
    "        \"fact\": \"_bridge\",\n",
    "        \"fact_ret\": \"_bridge\",\n",
    "        \"fact_inv\": \"_bridge\",\n",
    "    }\n",
    "}\n",
    "\n",
    "def materialize_queries(query_set: str):\n",
    "    \"\"\"\n",
    "    Expands QUERY_TEMPLATES into list[(name, dax)] for query_set (\"SS\" or \"USS\"),\n",
    "    swapping only the fact source(s).\n",
    "    \"\"\"\n",
    "    mapping = FACT_FOR_MEASURE_PREFIX[query_set]\n",
    "\n",
    "    out = []\n",
    "    for name, tmpl in QUERY_TEMPLATES:\n",
    "        q = tmpl.format(**mapping)\n",
    "        out.append((name, q))\n",
    "    return out\n",
    "\n",
    "SS_QUERIES = materialize_queries(\"SS\")\n",
    "USS_QUERIES = materialize_queries(\"USS\")\n",
    "\n",
    "# -------------------------\n",
    "# NEW: Distinct customers with orders\n",
    "# (SS: summarize per fact first, then union; USS: peripheral filter)\n",
    "# -------------------------\n",
    "P11_TEMPLATE = \"\"\"\n",
    "EVALUATE\n",
    "ROW(\n",
    "    \"Distinct Customers With Orders\",\n",
    "    CALCULATE(DISTINCTCOUNT('{fact}'[_key__dim__customer]), NOT ISBLANK('{fact}'[_measure__sales__ext_sales_price]))\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "SS_QUERIES.append((\"P11_distinct_customers_with_orders\", P11_TEMPLATE.format(**FACT_FOR_MEASURE_PREFIX[\"SS\"])))\n",
    "USS_QUERIES.append((\"P11_distinct_customers_with_orders\", P11_TEMPLATE.format(**FACT_FOR_MEASURE_PREFIX[\"USS\"])))\n",
    "\n",
    "QUERY_SETS = {\n",
    "    \"SS\": SS_QUERIES,\n",
    "    \"USS\": USS_QUERIES\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdd1c92-b762-4881-aed5-fbf893055e85",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a86079c-c8c9-4a70-9755-a17d533b5350",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def _stable_hash_df(df: pd.DataFrame) -> str:\n",
    "    if df is None:\n",
    "        return None\n",
    "    df2 = df.copy().reindex(sorted(df.columns), axis=1)\n",
    "    h = pd.util.hash_pandas_object(df2, index=True).values.astype(\"uint64\")\n",
    "    folded = np.bitwise_xor.reduce(h) if len(h) else np.uint64(0)\n",
    "    return str(int(folded))\n",
    "\n",
    "def _df_to_json_payload(df: pd.DataFrame, max_rows: int | None):\n",
    "    if df is None:\n",
    "        return None\n",
    "    truncated = False\n",
    "    if max_rows is not None and len(df) > max_rows:\n",
    "        df = df.head(max_rows)\n",
    "        truncated = True\n",
    "    return {\n",
    "        \"truncated\": truncated,\n",
    "        \"rows\": int(len(df)),\n",
    "        \"cols\": int(df.shape[1]),\n",
    "        \"columns\": list(df.columns),\n",
    "        \"data\": json.loads(df.to_json(orient=\"records\", date_format=\"iso\"))\n",
    "    }\n",
    "\n",
    "def run_one_dax(dataset_name: str, dax: str, workspace=None) -> pd.DataFrame:\n",
    "    return fabric.evaluate_dax(dataset=dataset_name, dax_string=dax, workspace=workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09475c90-1c04-4be7-a552-dab865b8ebef",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "def cv(values: list[float]) -> float:\n",
    "    if len(values) < 2:\n",
    "        return float(\"inf\")\n",
    "    mean = stats.fmean(values)\n",
    "    if mean == 0:\n",
    "        return float(\"inf\")\n",
    "    return stats.pstdev(values) / mean\n",
    "\n",
    "def run_query_adaptive(dataset_name: str, suite_key: str, qname: str, dax: str, workspace=None):\n",
    "    \"\"\"\n",
    "    Runs warmups + measured repetitions until stable by CV_TARGET or cap reached.\n",
    "    Stores all runs (warmup + measured).\n",
    "    Returns: (runs_rows, results_rows, stop_reason)\n",
    "    \"\"\"\n",
    "    runs_rows_local = []\n",
    "    results_rows_local = []\n",
    "\n",
    "    measured_durations = []\n",
    "    errors = 0\n",
    "    seq = 0\n",
    "    stop_reason = None\n",
    "\n",
    "    def record(run_phase: str, rep_n: int, duration_ms: float, df, err: str | None):\n",
    "        nonlocal seq\n",
    "        seq += 1\n",
    "        row_count = None if df is None else int(len(df))\n",
    "        col_count = None if df is None else int(df.shape[1])\n",
    "        result_hash = None if df is None else _stable_hash_df(df)\n",
    "        payload = _df_to_json_payload(df, MAX_RESULT_ROWS_TO_STORE)\n",
    "\n",
    "        runs_rows_local.append({\n",
    "            \"run_id\": run_id,\n",
    "            \"started_utc\": started_utc,\n",
    "            \"dataset\": dataset_name,\n",
    "            \"suite\": suite_key,\n",
    "            \"query_name\": qname,\n",
    "            \"phase\": run_phase,          # warmup / measured\n",
    "            \"repeat_n\": rep_n,           # within phase\n",
    "            \"seq_in_query\": seq,         # across phases\n",
    "            \"duration_ms\": float(duration_ms),\n",
    "            \"row_count\": row_count,\n",
    "            \"col_count\": col_count,\n",
    "            \"result_hash\": result_hash,\n",
    "            \"error\": err,\n",
    "        })\n",
    "\n",
    "        results_rows_local.append({\n",
    "            \"run_id\": run_id,\n",
    "            \"dataset\": dataset_name,\n",
    "            \"suite\": suite_key,\n",
    "            \"query_name\": qname,\n",
    "            \"phase\": run_phase,\n",
    "            \"repeat_n\": rep_n,\n",
    "            \"seq_in_query\": seq,\n",
    "            \"payload_json\": None if payload is None else json.dumps(payload)\n",
    "        })\n",
    "\n",
    "    # ---- Warmups (stored) ----\n",
    "    for w in range(1, WARMUP + 1):\n",
    "        t0 = time.perf_counter()\n",
    "        df = None\n",
    "        err = None\n",
    "        try:\n",
    "            df = run_one_dax(dataset_name, dax, workspace=workspace)\n",
    "        except Exception as e:\n",
    "            err = str(e); errors += 1\n",
    "        t1 = time.perf_counter()\n",
    "        record(\"warmup\", w, (t1 - t0) * 1000.0, df, err)\n",
    "\n",
    "    # ---- Measured runs (adaptive) ----\n",
    "    m = 0\n",
    "    while True:\n",
    "        m += 1\n",
    "        t0 = time.perf_counter()\n",
    "        df = None\n",
    "        err = None\n",
    "        try:\n",
    "            df = run_one_dax(dataset_name, dax, workspace=workspace)\n",
    "        except Exception as e:\n",
    "            err = str(e); errors += 1\n",
    "        t1 = time.perf_counter()\n",
    "\n",
    "        dur_ms = (t1 - t0) * 1000.0\n",
    "        record(\"measured\", m, dur_ms, df, err)\n",
    "\n",
    "        if err is None:\n",
    "            measured_durations.append(dur_ms)\n",
    "\n",
    "        # stop conditions\n",
    "        if errors >= ERROR_LIMIT:\n",
    "            stop_reason = \"error_limit\"\n",
    "            break\n",
    "\n",
    "        if m >= MAX_MEASURED:\n",
    "            stop_reason = \"max_measured\"\n",
    "            break\n",
    "\n",
    "        if len(measured_durations) >= MIN_MEASURED:\n",
    "            current_cv = cv(measured_durations)\n",
    "            if current_cv <= CV_TARGET:\n",
    "                stop_reason = f\"cv<={CV_TARGET}\"\n",
    "                break\n",
    "\n",
    "    # annotate stop reason on the LAST run row for this query\n",
    "    runs_rows_local[-1][\"stop_reason\"] = stop_reason\n",
    "\n",
    "    return runs_rows_local, results_rows_local, stop_reason"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5882df6-35e1-474b-b78e-8629c706788d",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddcf762-7861-4478-9eb5-2f7953dea142",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "run_id = str(uuid.uuid4())\n",
    "started_utc = pd.Timestamp.utcnow().isoformat()\n",
    "\n",
    "runs_rows = []\n",
    "results_rows = []\n",
    "\n",
    "for suite_key, dataset_name in DATASETS.items():\n",
    "    for (qname, dax) in QUERY_SETS[suite_key]:\n",
    "        rr, resr, stop_reason = run_query_adaptive(\n",
    "            dataset_name=dataset_name,\n",
    "            suite_key=suite_key,\n",
    "            qname=qname,\n",
    "            dax=dax,\n",
    "            workspace=WORKSPACE\n",
    "        )\n",
    "        runs_rows.extend(rr)\n",
    "        results_rows.extend(resr)\n",
    "        print(f\"[{suite_key}] {qname} stop_reason={stop_reason}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11c6f99-ee47-45cd-9e03-efba17a1000a",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8363475b-4f8f-4502-9db3-73d51866aa0b",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "runs_df = pd.DataFrame(runs_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a068ced5-8e23-4446-8ae5-364fbba44177",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "summary = (\n",
    "    runs_df\n",
    "    .query(\"phase == 'measured' and error.isna()\")\n",
    "    .groupby([\"dataset\", \"query_name\"], as_index=False)\n",
    "    .agg(\n",
    "        avg_duration_ms=(\"duration_ms\", \"mean\"),\n",
    "        median_duration_ms=(\"duration_ms\", \"median\"),\n",
    "        runs=(\"duration_ms\", \"count\")\n",
    "    )\n",
    ")\n",
    "\n",
    "display(summary)"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "33e98272-fa18-42b3-bf21-a77d800574d2",
    "default_lakehouse_name": "tpc_ds",
    "default_lakehouse_workspace_id": "2c17fce2-f59a-412f-8613-75891d6e07e1",
    "known_lakehouses": [
     {
      "id": "33e98272-fa18-42b3-bf21-a77d800574d2"
     }
    ]
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "synapse_widget": {
   "state": {
    "bbc573ef-baa8-4d57-bc0b-086b68c8f4ae": {
     "persist_state": {
      "view": {
       "chartOptions": {
        "aggregationType": "sum",
        "binsNumber": 10,
        "categoryFieldKeys": [],
        "chartType": "bar",
        "isStacked": false,
        "seriesFieldKeys": [],
        "wordFrequency": "-1"
       },
       "tableOptions": {},
       "type": "details",
       "viewOptionsGroup": [
        {
         "tabItems": [
          {
           "key": "0",
           "name": "Table",
           "options": {},
           "type": "table"
          },
          {
           "key": "3-u9km",
           "name": "By Dataset",
           "options": {
            "aggregationType": "avg",
            "binsNumber": 10,
            "categoryFieldKeys": [
             "0"
            ],
            "chartType": "bar",
            "isStacked": false,
            "legend": "none",
            "seriesFieldKeys": [
             "3"
            ],
            "subtitle": "By Query",
            "theme": "colorBlindSafe",
            "title": "DAX Benchmark",
            "wordFrequency": "-1",
            "xAxisStyle": {
             "label": "",
             "scale": "category"
            },
            "yAxisStyle": {
             "label": "Median Duration (ms)"
            }
           },
           "type": "chart"
          },
          {
           "key": "2-4u9e",
           "name": "By Query",
           "options": {
            "aggregationType": "avg",
            "binsNumber": 10,
            "categoryFieldKeys": [
             "1"
            ],
            "chartType": "bar",
            "isStacked": false,
            "legend": "top",
            "pivotFieldKey": "0",
            "seriesFieldKeys": [
             "3"
            ],
            "subtitle": "By Query",
            "theme": "colorBlindSafe",
            "title": "DAX Benchmark",
            "wordFrequency": "-1",
            "xAxisStyle": {
             "label": "Query",
             "scale": "category"
            },
            "yAxisStyle": {
             "label": "Median Duration (ms)"
            }
           },
           "type": "chart"
          }
         ]
        }
       ]
      }
     },
     "sync_state": {
      "isSummary": false,
      "language": "python",
      "table": {
       "rows": [
        {
         "0": "Star Schema",
         "1": "P10_store_sales_yoy_by_year",
         "2": "1057.05358832",
         "3": "723.3455895",
         "4": "100",
         "index": 0,
         "key": 0
        },
        {
         "0": "Star Schema",
         "1": "P11_distinct_customers_with_orders",
         "2": "5780.00353",
         "3": "5754.2353439999",
         "4": "5",
         "index": 1,
         "key": 1
        },
        {
         "0": "Star Schema",
         "1": "P1_store_sales_by_year",
         "2": "818.6831772",
         "3": "812.7541140002",
         "4": "5",
         "index": 2,
         "key": 2
        },
        {
         "0": "Star Schema",
         "1": "P2_store_sales_by_year_category",
         "2": "839.01571734",
         "3": "718.4715915",
         "4": "100",
         "index": 3,
         "key": 3
        },
        {
         "0": "Star Schema",
         "1": "P3_store_sales_many_groups",
         "2": "1025.84967565",
         "3": "844.0163434998",
         "4": "100",
         "index": 4,
         "key": 4
        },
        {
         "0": "Star Schema",
         "1": "P4_top100_items_store_sales_2002",
         "2": "1015.36565736",
         "3": "956.2718035002",
         "4": "100",
         "index": 5,
         "key": 5
        },
        {
         "0": "Star Schema",
         "1": "P5_net_store_sales_by_month",
         "2": "840.00209371",
         "3": "704.9605554998",
         "4": "100",
         "index": 6,
         "key": 6
        },
        {
         "0": "Star Schema",
         "1": "P7_total_sales_all_channels_by_year",
         "2": "1060.51397198",
         "3": "688.4478415",
         "4": "100",
         "index": 7,
         "key": 7
        },
        {
         "0": "Star Schema",
         "1": "P9_inventory_wh_category_year_2002",
         "2": "1070.27517928",
         "3": "699.2889234998",
         "4": "100",
         "index": 8,
         "key": 8
        },
        {
         "0": "Unified Star Schema",
         "1": "P10_store_sales_yoy_by_year",
         "2": "903.29551765",
         "3": "730.3458620004",
         "4": "100",
         "index": 9,
         "key": 9
        },
        {
         "0": "Unified Star Schema",
         "1": "P11_distinct_customers_with_orders",
         "2": "1026.05585211",
         "3": "697.6696799998",
         "4": "100",
         "index": 10,
         "key": 10
        },
        {
         "0": "Unified Star Schema",
         "1": "P1_store_sales_by_year",
         "2": "906.04732042",
         "3": "738.0701165",
         "4": "100",
         "index": 11,
         "key": 11
        },
        {
         "0": "Unified Star Schema",
         "1": "P2_store_sales_by_year_category",
         "2": "695.2800168",
         "3": "679.1677220003",
         "4": "5",
         "index": 12,
         "key": 12
        },
        {
         "0": "Unified Star Schema",
         "1": "P3_store_sales_many_groups",
         "2": "980.79889208",
         "3": "910.8423614998",
         "4": "100",
         "index": 13,
         "key": 13
        },
        {
         "0": "Unified Star Schema",
         "1": "P4_top100_items_store_sales_2002",
         "2": "1033.33988535",
         "3": "1012.0152110001",
         "4": "100",
         "index": 14,
         "key": 14
        },
        {
         "0": "Unified Star Schema",
         "1": "P5_net_store_sales_by_month",
         "2": "883.32476461",
         "3": "721.9645215",
         "4": "100",
         "index": 15,
         "key": 15
        },
        {
         "0": "Unified Star Schema",
         "1": "P7_total_sales_all_channels_by_year",
         "2": "1037.17717661",
         "3": "693.0912079997",
         "4": "100",
         "index": 16,
         "key": 16
        },
        {
         "0": "Unified Star Schema",
         "1": "P9_inventory_wh_category_year_2002",
         "2": "1059.43912379",
         "3": "718.0236715001",
         "4": "100",
         "index": 17,
         "key": 17
        }
       ],
       "schema": [
        {
         "key": "0",
         "name": "dataset",
         "type": "string"
        },
        {
         "key": "1",
         "name": "query_name",
         "type": "string"
        },
        {
         "key": "2",
         "name": "avg_duration_ms",
         "type": "double"
        },
        {
         "key": "3",
         "name": "median_duration_ms",
         "type": "double"
        },
        {
         "key": "4",
         "name": "runs",
         "type": "bigint"
        }
       ],
       "truncated": false
      },
      "wranglerEntryContext": {
       "candidateVariableNames": [
        "summary"
       ],
       "dataframeType": "pandas"
      }
     },
     "type": "Synapse.DataFrame"
    }
   },
   "version": "0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
